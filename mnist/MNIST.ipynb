{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MNIST.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"authorship_tag":"ABX9TyOCGpmlp4x4F3bJqhxnpoJA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5cJBqnKzzGQc"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision.datasets import MNIST, FashionMNIST, KMNIST, EMNIST, QMNIST\n","from torchvision.transforms import ToTensor\n","\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","%matplotlib inline "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WahcpBSDTnRw"},"source":["class CNN(nn.Module):\n","    def __init__(self, n_classes=10):\n","        super().__init__()\n","        \n","        self.features = nn.Sequential(\n","            nn.Conv2d(1, 128, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 128, 3, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(128, 128, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 128, 3, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(128, 128, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 128, 3, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","        )\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(128 * 7 * 7, 128),\n","            nn.ReLU(),\n","            nn.Dropout(.5),\n","            nn.Linear(128, n_classes),\n","        )\n","\n","    def forward(self, data):\n","        data = self.features(data)\n","        data = data.view(data.size()[0], -1)\n","        return self.classifier(data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J9lZGvk-2-6S"},"source":["class Agent:\n","    def __init__(self, model, data, lr=4e-4, lr_decay=.9, batch_size=64):\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","        self.model = model\n","        self.data = data\n","        self.name = data.__name__\n","\n","        self.lr = lr\n","        self.lr_decay = lr_decay\n","        self.loss_fn = nn.CrossEntropyLoss()\n","        self.optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","        self.train_data = data(self.name, train=True, download=True, transform=ToTensor())\n","        self.train_loader = torch.utils.data.DataLoader(self.train_data,\n","                                                      batch_size=batch_size,\n","                                                      shuffle=True)\n","        \n","        self.test_data = data(self.name, train=False, download=True, transform=ToTensor())\n","        self.test_loader = torch.utils.data.DataLoader(self.test_data,\n","                                                     batch_size=batch_size)\n","        \n","        self.model.to(self.device)\n","        self.loss_fn.to(self.device)\n","\n","        self.best = None\n","\n","        print('n_train', len(self.train_data))\n","        print('n_test', len(self.test_data))\n","        print('n_features', sum(p.numel() for p in self.model.features.parameters()))\n","        print('n_classifier', sum(p.numel() for p in self.model.classifier.parameters()))\n","        \n","    def train(self, epochs=10):\n","        self.optimizer.lr = self.lr\n","\n","        timestamp = time.time()\n","        for epoch in range(epochs):\n","            self.model.train()\n","\n","            train_loss = 0\n","            train_acc = 0\n","            train_cnt = 0\n","\n","            for images, labels in iter(self.train_loader):\n","                train_cnt += len(images)\n","\n","                images, labels = images.to(self.device), labels.to(self.device)\n","                \n","                self.optimizer.zero_grad()\n","\n","                prediction = self.model(images)\n","\n","                loss = self.loss_fn(prediction, labels)\n","                loss.backward()\n","\n","                self.optimizer.step()\n","\n","                train_loss += loss.item()\n","                success = (labels.data == prediction.max(dim=1)[1])\n","                train_acc += success.type(torch.FloatTensor).sum()\n","\n","            train_acc /= train_cnt\n","            test_acc, _ = self.test()\n","\n","            duration = time.gmtime(time.time() - timestamp)\n","\n","            print(f'epoch:{epoch+1:3d}',\n","                  f'   loss:{train_loss:9.3f}',\n","                  f'   train:{train_acc:.4f}',\n","                  f'   test:{test_acc:.4f}',\n","                  f'   lr:{self.optimizer.lr:.6f}',\n","                  time.strftime('   %X', duration),)\n","\n","            self.save_model(self.model, test_acc, train_acc, train_loss)\n","\n","            self.optimizer.lr *= self.lr_decay\n","\n","    def test(self):\n","        self.model.eval()\n","\n","        with torch.no_grad():\n","            \n","            accuracy = 0\n","            fail = []\n","            \n","            for i, (images, labels) in enumerate(self.test_loader):\n","                images, labels = images.to(self.device), labels.to(self.device)\n","\n","                prediction = self.model(images)\n","\n","                success = (labels.data == prediction.max(dim=1)[1])\n","\n","                fail.extend([i*len(images)+j\n","                             for j, x in enumerate(success) if not x])\n","\n","                accuracy += success.type(torch.FloatTensor).sum()\n","\n","            accuracy /= len(self.test_data)\n","\n","            return accuracy, fail\n","\n","    def save_model(self, model, test_acc, train_acc, train_loss):\n","        if self.is_better(test_acc, train_acc, train_loss):\n","            self.best = {\n","                'model': model.state_dict(),\n","                'test_acc': test_acc,\n","                'train_acc': train_acc,\n","                'train_loss': train_loss,\n","            }\n","\n","            torch.save(self.best, f'{self.name}.model')\n","\n","    def load_model(self, file_name=None):\n","        if file_name is None:\n","            file_name = f'{self.name}.model'\n","\n","        self.best = torch.load(file_name)\n","        self.model.load_state_dict(self.best['model'])\n","\n","    def is_better(self, test_acc, train_acc, train_loss):\n","        if self.best is None:\n","            return True\n","\n","        if self.best['test_acc'] != test_acc:\n","            return self.best['test_acc'] < test_acc\n","        if self.best['train_acc'] != train_acc:\n","            return self.best['train_acc'] < test_acc\n","        return self.best['train_loss'] < train_loss\n","\n","    def predict(self, n=None):\n","        if n is None:\n","            n = np.random.randint(0, len(self.test_data))\n","\n","        sample = torch.utils.data.Subset(self.test_data, [n])\n","        sample = torch.utils.data.DataLoader(sample, batch_size=1)\n","\n","        self.model.eval()\n","        softmax = nn.Softmax(dim=1)\n","\n","        for image, label in iter(sample):\n","            with torch.no_grad():\n","                predict = self.model(image.to(self.device))\n","\n","            image = image.detach().numpy().squeeze()\n","            label = f'\\n{n}: {self.data.classes[label.item()]}\\n'\n","            predict = predict.cpu()\n","            predict = softmax(predict).detach().numpy()[0]\n","            p_label = f'\\n{n}: {self.data.classes[np.argmax(predict)]}\\n'\n","\n","            plt.figure(figsize=(16,7))\n","\n","            plt.subplot(1,2,1)\n","            plt.imshow(image)\n","            plt.title(label, fontsize=36)\n","\n","            plt.subplot(1,2,2)\n","            sns.set(style=\"whitegrid\", color_codes=True)\n","            pal = sns.color_palette(\"coolwarm_r\", len(predict))\n","            rank = predict.argsort().argsort()\n","            sns.barplot(x=[self.data.classes[i] for i in range(len(predict))],\n","                        y=predict,\n","                        palette=np.array(pal[::-1])[rank])\n","            plt.title(p_label, fontsize=36)\n","            plt.xticks(rotation=70)\n","            plt.ylim(0, 1)\n","\n","            plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ikZ2ZAiI9q1p"},"source":["model = CNN()\n","agent = Agent(model, MNIST)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EVS77w4j4UnK"},"source":["acc, fail = agent.test()\n","\n","print(f'Accuracy: {acc:.4f}\\n')\n","print(f'Failed predictions: {fail}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IFnwrV-cEePa"},"source":["agent.predict(340)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jLd_OSsFutUH"},"source":["agent.train(40)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sbEL37gVYNn-"},"source":["agent.load_model()"],"execution_count":null,"outputs":[]}]}